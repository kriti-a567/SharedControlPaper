{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bb169378-75fe-47d9-950c-3dccdd8389bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "57c49acb-4c2d-45b1-ad5f-dce3265673e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c06c97b5-16af-47d4-ae1f-ea9d7fdc24f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Users/jahrios/Documents/Stanford/PoldrackLab/Projects/SharedControl/Data/raw/\"\n",
    "exp_stage = \"final/\"\n",
    "task = \"simple_stop\"\n",
    "\n",
    "pattern = os.path.join(data_path, exp_stage, '*', task, '*.csv')\n",
    "\n",
    "data_files = glob.glob(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f3306580-3115-4a1d-a547-61ab60f15649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject_label(file):\n",
    "    \n",
    "    match = re.search(r'/sub-(s\\d{3})/', file)\n",
    "    \n",
    "    if match:\n",
    "        subject_label = match.group(1)\n",
    "        print(\"Subject label:\", subject_label)\n",
    "        return subject_label\n",
    "    else:\n",
    "        print(\"No subject label found.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "77803d29-829d-415a-bbbf-69c6aa4d48c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_SSRT(df, max_go_rt = 2, violation_flag = False):\n",
    "    \n",
    "    df = df.query('Phase == \"test\"')\n",
    "    \n",
    "    go_trials = df.loc[df.trialType == 'go']\n",
    "    stop_df = df.loc[df.trialType == 'stop']\n",
    "\n",
    "    go_replacement_df = go_trials.where(~go_trials['rt'].isna(), max_go_rt)\n",
    "    sorted_go = go_replacement_df.rt.sort_values(ascending = True, ignore_index=True)\n",
    "    stop_failure = stop_df.loc[stop_df['rt'].notna()]\n",
    "\n",
    "    p_respond = len(stop_failure)/len(stop_df)\n",
    "    avg_SSD = stop_df.ssd.mean()\n",
    "\n",
    "    nth_index = int(np.rint(p_respond*len(sorted_go))) - 1\n",
    "\n",
    "    if nth_index < 0:\n",
    "        nth_RT = sorted_go[0]\n",
    "    elif nth_index >= len(sorted_go):\n",
    "        nth_RT = sorted_go[-1]\n",
    "    else:\n",
    "        nth_RT = sorted_go[nth_index]\n",
    "\n",
    "    SSRT = nth_RT - avg_SSD\n",
    "\n",
    "    return SSRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3e99deab-a8fc-49a4-a03d-41c66329fb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_stop_data(df):\n",
    "    df = df.query(f'Phase == \"test\"')\n",
    "    df = df[['Block', 'Phase', 'trialType', 'goStim', 'correctResponse', 'ssd', 'goResp_test.keys', 'goResp_test.corr','goResp_test.rt']]\n",
    "    \n",
    "    df.loc[:, 'stop_acc'] = np.where(df['trialType'] == 'stop', \n",
    "                                 np.where(df['goResp_test.keys'] == 'None', 1, 0), \n",
    "                                 np.nan)\n",
    "\n",
    "    df.loc[:, 'go_acc'] = np.where(df['trialType'] == 'go', \n",
    "                                   np.where(df['goResp_test.keys'] == df['correctResponse'], 1, 0), \n",
    "                                   np.nan)\n",
    "\n",
    "    df.loc[:, 'stop_failure_acc'] = np.where(\n",
    "        (df['trialType'] == 'stop') & (df['goResp_test.rt'].notna()),\n",
    "        np.where(df['goResp_test.keys'] == df['correctResponse'], 1, 0),\n",
    "        np.nan)\n",
    "    \n",
    "    df.rename(columns={'goResp_test.keys': 'response', 'goResp_test.corr': 'correct', 'goResp_test.rt': 'rt'}, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fdcf27be-b83f-4c35-908b-1f7136feac96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject label: s016\n",
      "Subject label: s011\n",
      "Subject label: s018\n",
      "Subject label: s019\n",
      "Subject label: s010\n",
      "Subject label: s017\n",
      "Subject label: s004\n",
      "Subject label: s005\n",
      "Subject label: s012\n",
      "Subject label: s015\n",
      "Subject label: s014\n",
      "Subject label: s013\n",
      "Subject label: s009\n",
      "Subject label: s007\n",
      "Subject label: s006\n",
      "Subject label: s008\n"
     ]
    }
   ],
   "source": [
    "task_metrics = {}\n",
    "for file in data_files:\n",
    "    \n",
    "    subject_label = get_subject_label(file)\n",
    "    \n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    df = preprocess_stop_data(df)\n",
    "    \n",
    "    \n",
    "    go_rt = df.query(\"trialType == 'go'\").rt.mean()\n",
    "    stop_fail_rt = df.query(\"trialType == 'stop'\").rt.mean()\n",
    "    go_acc = df.query(\"trialType == 'go'\").go_acc.mean()\n",
    "    stop_failure_acc = df.query(\"trialType == 'stop'\").stop_failure_acc.mean()\n",
    "    stop_success = df.query(\"trialType == 'stop'\").stop_acc.mean()\n",
    "    avg_ssd = df.query(\"trialType == 'stop'\").ssd.mean()\n",
    "    min_ssd = df.query(\"trialType == 'stop'\").ssd.min()\n",
    "    max_ssd = df.query(\"trialType == 'stop'\").ssd.max()\n",
    "    min_ssd_count = (df.query(\"trialType == 'stop'\").ssd == min_ssd).sum()\n",
    "    max_ssd_count = (df.query(\"trialType == 'stop'\").ssd == max_ssd).sum()\n",
    "    ssrt = compute_SSRT(df)\n",
    "    \n",
    "    \n",
    "    \n",
    "    task_metrics[subject_label] = {\n",
    "            'go_rt': go_rt,\n",
    "            'stop_fail_rt': stop_fail_rt,\n",
    "            'go_acc': go_acc,\n",
    "            'stop_failure_acc': stop_failure_acc,\n",
    "            'stop_success': stop_success,\n",
    "            'avg_ssd': avg_ssd,\n",
    "            'min_ssd': min_ssd,\n",
    "            'max_ssd': max_ssd,\n",
    "            'min_ssd_count': min_ssd_count,\n",
    "            'max_ssd_count': max_ssd_count,\n",
    "            'ssrt': ssrt\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "20496baf-9292-49ec-b172-8931f4d25ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(task_metrics).T\n",
    "metrics = metrics.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9e36ec9a-1a3f-4bb0-9b8d-fcdde97c8c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.to_csv('output/simple_stop_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead0d825-cdc6-4d0d-b363-47d5376a3146",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
