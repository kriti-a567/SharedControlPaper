{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import ptitprince as pt\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_control_ssrt = pd.read_csv(\"/Users/kritiaxh/Documents/PoldrackLab/SharedControl/notebooks/analysis/output/shared_control_metrics_ssrt.csv\")\n",
    "simple_stop_ssrt = pd.read_csv(\"/Users/kritiaxh/Documents/PoldrackLab/SharedControl/notebooks/analysis/output/simple_stop_metrics.csv\")\n",
    "participant_tracking = pd.read_csv('/Users/kritiaxh/Documents/PoldrackLab/SharedControl/data/participant_tracking.csv')\n",
    "survey_results = pd.read_csv('/Users/kritiaxh/Documents/PoldrackLab/SharedControl/notebooks/analysis/output/survey_scores.csv')\n",
    "go_task_accuracy_before_stop_onset = pd.read_csv('/Users/kritiaxh/Documents/PoldrackLab/SharedControl/notebooks/analysis/output/shared_control_metrics_go_task_accuracy_before_stop_onset.csv')\n",
    "duration_of_inhibition = pd.read_csv(\"/Users/kritiaxh/Documents/PoldrackLab/SharedControl/notebooks/analysis/output/shared_control_metrics_duration_of_inhibition.csv\")\n",
    "proportion_of_trials_with_stop_moment = pd.read_csv(\"/Users/kritiaxh/Documents/PoldrackLab/SharedControl/notebooks/analysis/output/proportion_of_trials_with_stop_moment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the first column as the index to use for merging (assuming it's the subject ID)\n",
    "shared_control_ssrt.columns = ['subject_id'] + list(shared_control_ssrt.columns[1:])\n",
    "simple_stop_ssrt.columns = ['subject_id'] + list(simple_stop_ssrt.columns[1:])\n",
    "\n",
    "# Merge by the first (subject_id) column\n",
    "merged_df = pd.merge(shared_control_ssrt, simple_stop_ssrt[['subject_id', 'ssrt']], on='subject_id', how='left')\n",
    "\n",
    "# Rename columns\n",
    "merged_df.rename(columns={'ssrt': 'simple_stop_ssrt', 'ai_ssrt': 'ai_disengaged_ssrt', 'ai_ai_ssrt': 'ai_engaged_ssrt'}, inplace=True)\n",
    "\n",
    "# Remove the last row, assuming it's the mean row\n",
    "merged_df = merged_df.iloc[:-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.265243697571541 0.0332693728193312\n",
      "0.36505181602953457\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "mean_df = np.mean(merged_df[\"ai_disengaged_ssrt\"])\n",
    "mean_std = np.std(merged_df[\"ai_disengaged_ssrt\"])\n",
    "print(mean_df, mean_std)\n",
    "print(mean_df + 3*mean_std)\n",
    "print((merged_df[\"non_ai_ssrt\"] > merged_df[\"ai_disengaged_ssrt\"]).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planned Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data for repeated measures ANOVA\n",
    "data_long = pd.melt(merged_df, id_vars=['subject_id'], value_vars=['non_ai_ssrt', 'ai_disengaged_ssrt', 'simple_stop_ssrt'],\n",
    "                    var_name='condition', value_name='SSRT')\n",
    "\n",
    "\n",
    "# Run the repeated measures ANOVA\n",
    "aovrm = AnovaRM(data_long, 'SSRT', 'subject_id', within=['condition'])\n",
    "anova_results = aovrm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Disengaged vs Non-AI SSRT Comparison: t-statistic = 5.616398897831615, p-value = 1.765719683873891e-06\n",
      "Non-AI vs Simple Stopping SSRT Comparison: t-statistic = 6.362698988629167, p-value = 1.624591647785976e-07\n",
      "0.4964312947048828\n"
     ]
    }
   ],
   "source": [
    "# Conduct the paired t-tests for planned comparisons\n",
    "\n",
    "# Comparison 1: AI Stop vs non-AI Stop\n",
    "ai_vs_non_ai = stats.ttest_rel(merged_df['ai_disengaged_ssrt'], merged_df['non_ai_ssrt'])\n",
    "print(f\"AI Disengaged vs Non-AI SSRT Comparison: t-statistic = {ai_vs_non_ai.statistic}, p-value = {ai_vs_non_ai.pvalue}\")\n",
    "\n",
    "# Comparison 2: Non-AI vs Simple Stopping\n",
    "non_ai_vs_simple = stats.ttest_rel(merged_df['non_ai_ssrt'], merged_df['simple_stop_ssrt'])\n",
    "non_ai_vs_simple_corr = np.corrcoef(merged_df['non_ai_ssrt'], merged_df['simple_stop_ssrt'])[1][0]\n",
    "print(f\"Non-AI vs Simple Stopping SSRT Comparison: t-statistic = {non_ai_vs_simple.statistic}, p-value = {non_ai_vs_simple.pvalue}\")\n",
    "print(non_ai_vs_simple_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non AI SSRT: 1.1611734733567018, 0.2528248670945422\n",
      "AI SSRT: 1.1971064010639385, 0.23882163492528155\n",
      "AI AI SSRT: -0.2799797706417339, 0.7814164780857645\n",
      "T-statistic for AI - Non-AI difference between groups: 0.47, P-value: 0.6411\n"
     ]
    }
   ],
   "source": [
    "# Calculate order effects between AI being first or Non-AI being first\n",
    "non_ai_first_subs = participant_tracking[participant_tracking[\"Cond Order\"] == 1][\"Subject\"].to_list()\n",
    "ai_first_subs = participant_tracking[participant_tracking[\"Cond Order\"] == 2][\"Subject\"].to_list()\n",
    "\n",
    "ssrt_non_ai_first_non_ai = []\n",
    "ssrt_ai_first_non_ai = []\n",
    "ssrt_non_ai_first_ai = []\n",
    "ssrt_ai_first_ai = []\n",
    "ssrt_non_ai_first_ai_ai = []\n",
    "ssrt_ai_first_ai_ai = []\n",
    "\n",
    "for sub in non_ai_first_subs:\n",
    "    ssrt = shared_control_ssrt[shared_control_ssrt['subject_id'] == sub][\"non_ai_ssrt\"].values\n",
    "    ssrt_non_ai_first_non_ai.append(ssrt[0])\n",
    "    ssrt = shared_control_ssrt[shared_control_ssrt['subject_id'] == sub][\"ai_ssrt\"].values\n",
    "    ssrt_non_ai_first_ai.append(ssrt[0])\n",
    "    ssrt = shared_control_ssrt[shared_control_ssrt['subject_id'] == sub][\"ai_ai_ssrt\"].values\n",
    "    ssrt_non_ai_first_ai_ai.append(ssrt[0])\n",
    "\n",
    "for sub in ai_first_subs:\n",
    "    ssrt = shared_control_ssrt[shared_control_ssrt['subject_id'] == sub][\"non_ai_ssrt\"].values\n",
    "    ssrt_ai_first_non_ai.append(ssrt[0])\n",
    "    ssrt = shared_control_ssrt[shared_control_ssrt['subject_id'] == sub][\"ai_ssrt\"].values\n",
    "    ssrt_ai_first_ai.append(ssrt[0])\n",
    "    ssrt = shared_control_ssrt[shared_control_ssrt['subject_id'] == sub][\"ai_ai_ssrt\"].values\n",
    "    ssrt_ai_first_ai_ai.append(ssrt[0])\n",
    "\n",
    "t_stat, p_value = stats.ttest_ind(ssrt_ai_first_non_ai, ssrt_non_ai_first_non_ai, equal_var=False)\n",
    "print(f'Non AI SSRT: {t_stat}, {p_value}')\n",
    "t_stat, p_value = stats.ttest_ind(ssrt_ai_first_ai, ssrt_non_ai_first_ai, equal_var=False)\n",
    "print(f'AI SSRT: {t_stat}, {p_value}')\n",
    "t_stat, p_value = stats.ttest_ind(ssrt_ai_first_ai_ai, ssrt_non_ai_first_ai_ai, equal_var=False)\n",
    "print(f'AI AI SSRT: {t_stat}, {p_value}')\n",
    "\n",
    "# Calculate the differences between AI SSRT and Non-AI SSRT for both subject groups\n",
    "diff_non_ai_first = np.array(ssrt_non_ai_first_ai) - np.array(ssrt_non_ai_first_non_ai)  # AI - Non-AI for Non-AI first subjects\n",
    "diff_ai_first = np.array(ssrt_ai_first_ai) - np.array(ssrt_ai_first_non_ai)  # AI - Non-AI for AI first subjects\n",
    "t_stat_diff, p_value_diff = stats.ttest_ind(diff_ai_first, diff_non_ai_first, equal_var=False)\n",
    "print(f'T-statistic for AI - Non-AI difference between groups: {t_stat_diff:.2f}, P-value: {p_value_diff:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a raincloud plot of Difference in AI - Non AI SSRT for subjects who had the AI block first vs Non AI block first\n",
    "data_to_plot = {\n",
    "    'Condition': ['Non-AI First'] * len(diff_non_ai_first) + ['AI First'] * len(diff_ai_first),\n",
    "    'Difference': np.concatenate((diff_non_ai_first, diff_ai_first))\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "plot_df = pd.DataFrame(data_to_plot)\n",
    "\n",
    "# Set up the figure for the raincloud plots\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create the raincloud plot\n",
    "ax = plt.gca()  # Get the current axes\n",
    "raincloud = pt.RainCloud(\n",
    "    x='Condition', \n",
    "    y='Difference', \n",
    "    data=plot_df,\n",
    "    palette={\"Non-AI First\": \"teal\", \n",
    "             \"AI First\": \"chocolate\"},\n",
    "    width_viol=0.6, \n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Add titles and labels\n",
    "ax.set_title('Raincloud Plot of SSRT Differences for Non-AI First vs AI First Conditions')\n",
    "ax.set_xlabel('Condition')\n",
    "ax.set_ylabel('Difference in SSRT (AI-Disengaged - Non-AI)')\n",
    "ax.grid()\n",
    "\n",
    "# Save and show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/order_effects_raincloud_plot.png', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create plots for QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a line plot of SSRT\n",
    "# Plotting the SSRT distributions together\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot each condition's SSRT on the same axes\n",
    "plt.plot(merged_df['subject_id'], merged_df['non_ai_ssrt'], label='Non-AI SSRT', marker='o', color='blue')\n",
    "plt.plot(merged_df['subject_id'], merged_df['ai_disengaged_ssrt'], label='AI Disengaged SSRT', marker='o', color='red')\n",
    "plt.plot(merged_df['subject_id'], merged_df['ai_engaged_ssrt'], label='AI Engaged SSRT', marker='o', color='green')\n",
    "plt.plot(merged_df['subject_id'], merged_df['simple_stop_ssrt'], label='Simple Stop SSRT', marker='o', color='purple')\n",
    "\n",
    "# Titles and labels\n",
    "plt.title('Comparison of SSRT Distributions')\n",
    "plt.xlabel('Subject ID')\n",
    "plt.ylabel('SSRT (s)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure and show\n",
    "plt.savefig('figures/ssrt_distributions_comparison.png', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raincloud plot for AI vs Non AI SSRT\n",
    "# Set up the figure for the raincloud plots\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Combine the data into a long format suitable for Seaborn\n",
    "melted_df = merged_df.melt(id_vars='subject_id', value_vars=['non_ai_ssrt', 'ai_disengaged_ssrt'],\n",
    "                            var_name='Condition', value_name='SSRT')\n",
    "melted_df['SSRT'] *= 1000  # Convert to milliseconds\n",
    "\n",
    "# Create a new axis for the plot\n",
    "ax = plt.gca()  # Get the current axes\n",
    "\n",
    "# Create the raincloud plot\n",
    "raincloud = pt.RainCloud(x='Condition', y='SSRT', data=melted_df,\n",
    "                          palette={\"non_ai_ssrt\": \"teal\", \"ai_disengaged_ssrt\": \"chocolate\"},\n",
    "                          width_viol=0.6, ax=ax)\n",
    "\n",
    "# Add titles and labels\n",
    "ax.set_title('non_ai_and_ai_disengaged_ssrt')\n",
    "ax.set_xlabel('Condition')\n",
    "ax.set_ylabel('SSRT (ms)')\n",
    "ax.grid()\n",
    "\n",
    "# Save and show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/ai_disengaged_vs_non_ai_ssrt_raincloud_plots.png', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/seaborn/_core.py:991: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n"
     ]
    }
   ],
   "source": [
    "ax = sns.lineplot(x='Condition', y='SSRT', data=melted_df, hue='subject_id', marker='o',\n",
    "                  palette=['#3C74BC'] * len(melted_df['subject_id'].unique()), legend=False)\n",
    "ax.set_title('non_ai_and_ai_disengaged_ssrt_by_subject')\n",
    "ax.set_ylabel('SSRT (ms)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/non_ai_and_ai_disengaged_ssrt_by_subject.png', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_of_inhibition.reset_index(inplace=True)\n",
    "duration_of_inhibition.rename(columns={duration_of_inhibition.columns[0]: 'subject_id',\n",
    "                                       'ai_duration_of_inhibition': 'ai_disengaged_duration_of_inhibition'}, inplace=True)\n",
    "\n",
    "melted_df = duration_of_inhibition.melt(\n",
    "    id_vars='subject_id', \n",
    "    value_vars=[\n",
    "        'non_ai_duration_of_inhibition', \n",
    "        'ai_disengaged_duration_of_inhibition'\n",
    "    ],\n",
    "    var_name='Condition', \n",
    "    value_name='Duration of Inhibition'\n",
    ")\n",
    "\n",
    "melted_df['Duration of Inhibition'] *= 1000  # Convert to milliseconds\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create the raincloud plot\n",
    "ax = plt.gca()  # Get the current axes\n",
    "raincloud = pt.RainCloud(\n",
    "    x='Condition', \n",
    "    y='Duration of Inhibition', \n",
    "    data=melted_df,\n",
    "    palette={\"non_ai_duration_of_inhibition\": \"teal\", \n",
    "             \"ai_disengaged_duration_of_inhibition\": \"chocolate\"},\n",
    "    width_viol=0.6, \n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Add titles and labels\n",
    "ax.set_title('Non-AI vs AI Disengaged Duration of Inhibition')\n",
    "ax.set_xlabel('Condition')\n",
    "ax.set_ylabel('Duration of Inhibition (ms)')\n",
    "ax.grid()\n",
    "\n",
    "# Save and show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/non_ai_vs_ai_duration_of_inhibition_raincloud_plots.png', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create violin plots of all SSRT\n",
    "# Set up the figure for the violin plots\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Combine the data into a long format suitable for Seaborn\n",
    "melted_df = merged_df.melt(id_vars='subject_id', value_vars=['non_ai_ssrt', 'ai_disengaged_ssrt', 'ai_engaged_ssrt', 'simple_stop_ssrt'],\n",
    "                            var_name='Condition', value_name='SSRT')\n",
    "melted_df['SSRT'] *= 1000\n",
    "# Create violin plots\n",
    "sns.violinplot(x='Condition', y='SSRT', data=melted_df, palette={\"non_ai_ssrt\": \"teal\", \"ai_disengaged_ssrt\": \"chocolate\", 'ai_engaged_ssrt': \"darkgray\", 'simple_stop_ssrt': \"lightsalmon\"})\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('SSRT_by_condition')\n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('SSRT (ms)')\n",
    "plt.grid()\n",
    "\n",
    "# Save and show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/all_ssrt_violin_plots.png', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_raincloud_plot(df, y_axis_name, multiply=0):\n",
    "    \"\"\"\n",
    "    Create a raincloud plot for proportions of trials with stop moments by condition.\n",
    "\n",
    "    Parameters:\n",
    "    - df: The DataFrame containing the data.\n",
    "    - y_axis_name: Name of y axis\n",
    "    \"\"\"\n",
    "    frame_name = [name for name, val in inspect.currentframe().f_back.f_locals.items() if val is df][0]\n",
    "    # Set up the figure for the raincloud plots\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Reset index\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    # Rename specific columns\n",
    "    new_columns = list(df.columns)\n",
    "    new_columns[1] = 'subject_id'  # Ensure 3rd column is subject_id\n",
    "    new_columns[2] = 'non_ai'  # Rename 5th column to non_ai\n",
    "    new_columns[3] = 'ai_disengaged'  # Rename 6th column to ai_disengaged\n",
    "    new_columns[4] = 'ai_engaged'  # Rename 7th column to ai_engaged\n",
    "    df.columns = new_columns  # Assign new column names\n",
    "\n",
    "    # Melt the dataframe to long format\n",
    "    melted_df = df.melt(\n",
    "        id_vars='subject_id', \n",
    "        value_vars=['non_ai', 'ai_disengaged', 'ai_engaged'],\n",
    "        var_name='Condition', \n",
    "        value_name=y_axis_name\n",
    "    )\n",
    "\n",
    "    if multiply == 1:\n",
    "        melted_df[y_axis_name] *= 1000\n",
    "\n",
    "    # Create the raincloud plot\n",
    "    ax = plt.gca()  # Get the current axes\n",
    "    raincloud = pt.RainCloud(\n",
    "        x='Condition', \n",
    "        y=y_axis_name, \n",
    "        data=melted_df,\n",
    "        palette={\"non_ai\": \"teal\", \n",
    "                 \"ai_disengaged\": \"chocolate\", \n",
    "                 \"ai_engaged\": \"darkgray\"},\n",
    "        width_viol=0.6, \n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    # Add titles and labels\n",
    "    ax.set_title(f'{frame_name}')\n",
    "    ax.set_xlabel('Condition')\n",
    "    ax.set_ylabel(y_axis_name)\n",
    "    ax.grid()\n",
    "\n",
    "    # Save and show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'figures/{frame_name}.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Raincloud plot saved as {frame_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raincloud plot saved as proportion_of_trials_with_stop_moment\n"
     ]
    }
   ],
   "source": [
    "create_raincloud_plot(proportion_of_trials_with_stop_moment, 'Proportion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raincloud plot saved as go_task_accuracy_before_stop_onset\n"
     ]
    }
   ],
   "source": [
    "create_raincloud_plot(go_task_accuracy_before_stop_onset, 'Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create violin plots of AI - Non AI SSRT in proactive vs non-proactive slowing subjects\n",
    "\n",
    "# Identify non-proactive slowing subjects\n",
    "non_proactive_slowing_subs = (go_task_accuracy_before_stop_onset['non_ai'] > \n",
    "                              go_task_accuracy_before_stop_onset['ai_disengaged'])\n",
    "non_proactive_subjects = go_task_accuracy_before_stop_onset.index[non_proactive_slowing_subs].tolist()\n",
    "\n",
    "# Extract SSRT values for AI and Non-AI conditions\n",
    "ssrt_non_ai = shared_control_ssrt['non_ai_ssrt']\n",
    "ssrt_ai = shared_control_ssrt['ai_ssrt']\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "plot_data = pd.DataFrame({\n",
    "    'subject_id': shared_control_ssrt.index,\n",
    "    'ssrt_non_ai': ssrt_non_ai,\n",
    "    'ssrt_ai': ssrt_ai\n",
    "})\n",
    "\n",
    "# Calculate the difference between AI SSRT and Non-AI SSRT\n",
    "plot_data['difference'] = plot_data['ssrt_ai'] - plot_data['ssrt_non_ai']\n",
    "\n",
    "# Classify subjects based on proactive slowing\n",
    "plot_data['slowing_type'] = ['Non-Proactive' if subject in non_proactive_subjects else 'Proactive' \n",
    "                              for subject in plot_data['subject_id']]\n",
    "\n",
    "plot_data['difference_ms'] = plot_data['difference'] * 1000\n",
    "\n",
    "violin_data = plot_data[['difference_ms', 'slowing_type']]\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.violinplot(x='slowing_type', y='difference_ms', data=violin_data, palette={'Non-Proactive': 'skyblue', 'Proactive': 'thistle'})\n",
    "plt.title('Difference in SSRT for Proactive vs Non-Proactive Subjects')\n",
    "plt.xlabel('Slowing Type')\n",
    "plt.ylabel('Difference in SSRT (AI - Non-AI) (ms)')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/ssrt_difference_proactive_vs_non_proactive.png', dpi=300) \n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8s/r02gjh_90hqdkx4nmh9szbsw0000gn/T/ipykernel_19969/3654082356.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  non_proactive_slowing_data.rename(columns={'ssrt_ai': 'ssrt_ai_disengaged'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "non_proactive_slowing_data = plot_data[plot_data['slowing_type'] == 'Non-Proactive']\n",
    "# Combine the data into a long format suitable for Seaborn\n",
    "non_proactive_slowing_data.rename(columns={'ssrt_ai': 'ssrt_ai_disengaged'}, inplace=True)\n",
    "melted_df = non_proactive_slowing_data.melt(id_vars='subject_id', value_vars=['ssrt_non_ai', 'ssrt_ai_disengaged'],\n",
    "                            var_name='Condition', value_name='SSRT')\n",
    "melted_df['SSRT'] *= 1000  # Convert to milliseconds\n",
    "\n",
    "# Create a new axis for the plot\n",
    "ax = plt.gca()  # Get the current axes\n",
    "\n",
    "# Create the raincloud plot\n",
    "raincloud = pt.RainCloud(x='Condition', y='SSRT', data=melted_df,\n",
    "                          palette={\"ssrt_non_ai\": \"teal\", \"ssrt_ai_disengaged\": \"chocolate\"},\n",
    "                          width_viol=0.6, ax=ax)\n",
    "\n",
    "# Add titles and labels\n",
    "ax.set_title('non_ai_and_ai_disengaged_ssrt_in_non_proactive_slowing_subjects')\n",
    "ax.set_xlabel('Condition')\n",
    "ax.set_ylabel('SSRT (ms)')\n",
    "ax.grid()\n",
    "\n",
    "# Save and show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/non_ai_and_ai_disengaged_ssrt_in_non_proactive_slowing_subjects.png', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory T-tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: -3.370, P-value: 0.0017\n"
     ]
    }
   ],
   "source": [
    "# T test for AI vs Non AI Duration of inhibition\n",
    "t_stat, p_value = stats.ttest_rel(duration_of_inhibition['non_ai_duration_of_inhibition'], duration_of_inhibition['ai_disengaged_duration_of_inhibition'])\n",
    "# Print the t-statistic and p-value\n",
    "print(f\"T-statistic: {t_stat:.3f}, P-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: -2.877, P-value: 0.0064\n"
     ]
    }
   ],
   "source": [
    "# T test for AI vs Non AI Go task accuracy before stop onset\n",
    "t_stat, p_value = stats.ttest_rel(go_task_accuracy_before_stop_onset['non_ai'], go_task_accuracy_before_stop_onset['ai_disengaged'])\n",
    "\n",
    "# Print the t-statistic and p-value\n",
    "print(f\"T-statistic: {t_stat:.3f}, P-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: -2.666, P-value: 0.0258\n"
     ]
    }
   ],
   "source": [
    "# T-test for difference in Non AI and AI SSRT in subjects who didn't show proactive slowing\n",
    "t_stat, p_value = stats.ttest_rel(non_proactive_slowing_data['ssrt_non_ai'], non_proactive_slowing_data['ssrt_ai_disengaged'])\n",
    "print(f\"T-statistic: {t_stat:.3f}, P-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.346220775309853 19.74513917149492\n",
      "T-statistic: 0.87, P-value: 0.3909\n"
     ]
    }
   ],
   "source": [
    "#T test for difference between Non AI and AI SSRT in subjects who showed and didn't show proactive slowing\n",
    "non_proactive_differences = plot_data[plot_data['slowing_type'] == 'Non-Proactive']['difference_ms']\n",
    "proactive_differences = plot_data[plot_data['slowing_type'] == 'Proactive']['difference_ms']\n",
    "print(np.mean(non_proactive_differences), np.mean(proactive_differences))\n",
    "t_stat, p_value = stats.ttest_ind(non_proactive_differences, proactive_differences, nan_policy='omit')\n",
    "print(f\"T-statistic: {t_stat:.2f}, P-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlate and plot survey scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlate_and_plot_survey_scores(column_name):\n",
    "    #Find the correlation between the survey score and the difference between AI Stop SSRT and Non AI SSRT for each subject\n",
    "    # Merge without duplicates\n",
    "    avg_df = merged_df.merge(survey_results, on='subject_id', how='left')\n",
    "\n",
    "    # Compute the difference between ai and non-ai SSRT\n",
    "    avg_df['difference_ai_disengaged_and_non_ai_ssrt'] = avg_df['ai_disengaged_ssrt'] - avg_df['non_ai_ssrt']\n",
    "\n",
    "    # Compute the correlation\n",
    "    correlation, pval = stats.pearsonr(avg_df[\"difference_ai_disengaged_and_non_ai_ssrt\"], avg_df[column_name])\n",
    "    print(f\"Correlation and p-value between SSRT and survey scores: {correlation}, {pval}\")\n",
    "\n",
    "    avg_df.to_csv(f'/Users/kritiaxh/Documents/PoldrackLab/SharedControl/notebooks/analysis/output/{column_name}_survey_by_ssrt.csv')\n",
    "\n",
    "    avg_df['difference_ai_disengaged_and_non_ai_ssrt'] *= 1000 #convert to ms\n",
    "\n",
    "    # Create a scatter plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(avg_df['difference_ai_disengaged_and_non_ai_ssrt'], avg_df['average_score'], alpha=0.7)\n",
    "    plt.title(f'Scatter Plot: {column_name} by SSRT')\n",
    "    plt.xlabel('Difference between AI-Disengaged and Non AI SSRT (ms)')\n",
    "    plt.ylabel('Survey Scores')\n",
    "    plt.grid()\n",
    "    plt.axhline(0, color='red', linestyle='--')  # Optional: Add a line at y = 0 for reference\n",
    "    plt.axvline(0, color='red', linestyle='--')  # Optional: Add a line at x = 0 for reference\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'/Users/kritiaxh/Documents/PoldrackLab/SharedControl/notebooks/analysis/figures/{column_name}_survey_by_ssrt.png', dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation and p-value between SSRT and survey scores: -0.050273491800991776, 0.7580291327103851\n"
     ]
    }
   ],
   "source": [
    "correlate_and_plot_survey_scores('average_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation and p-value between SSRT and survey scores: -0.05027349180099174, 0.7580291327103851\n"
     ]
    }
   ],
   "source": [
    "correlate_and_plot_survey_scores('total_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation and p-value between SSRT and survey scores: -0.17099934698418437, 0.29142729500524267\n"
     ]
    }
   ],
   "source": [
    "correlate_and_plot_survey_scores('I trust artificial intelligence.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation and p-value between SSRT and survey scores: 0.11183214465404323, 0.49206989228173403\n"
     ]
    }
   ],
   "source": [
    "correlate_and_plot_survey_scores('More vehicles, software, and appliances should make use of AI.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation and p-value between SSRT and survey scores: 0.2090744568757621, 0.19541108767886145\n"
     ]
    }
   ],
   "source": [
    "correlate_and_plot_survey_scores('I trust companies that do not use AI over companies that do.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation and p-value between SSRT and survey scores: -0.035368902016636214, 0.8284678948707205\n"
     ]
    }
   ],
   "source": [
    "correlate_and_plot_survey_scores('I would prefer to drive a self-driving car over a regular car.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation and p-value between SSRT and survey scores: -0.09080088862357336, 0.5773783666904873\n"
     ]
    }
   ],
   "source": [
    "correlate_and_plot_survey_scores('I trust a self driving car to drive safer than I would normally.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation and p-value between SSRT and survey scores: -0.17317277082821975, 0.28524536528152894\n"
     ]
    }
   ],
   "source": [
    "correlate_and_plot_survey_scores('I believe that increased use of artificial intelligence will make the world a safer place.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation and p-value between SSRT and survey scores: -0.06102390689638161, 0.7083599886190366\n"
     ]
    }
   ],
   "source": [
    "correlate_and_plot_survey_scores('AI is making our daily lives easier.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_responses_to_survey(column_name):\n",
    "    \"\"\"\n",
    "    Generate a bar chart of responses for a specific survey question.\n",
    "    \n",
    "    Parameters:\n",
    "    - column_name: The text of the survey question.\n",
    "    - survey_results: A dictionary containing survey responses with subject ID mapping.\n",
    "    \"\"\"\n",
    "    # Handle reverse coding for the specific question\n",
    "    if column_name == \"I trust companies that do not use AI over companies that do.\":\n",
    "        survey_results[column_name] = 6 - survey_results[column_name]\n",
    "\n",
    "    response_counts = np.bincount(survey_results[column_name].dropna().astype(int), minlength=6)[1:]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(np.arange(1, 6), response_counts, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "    plt.xticks(np.arange(1, 6)) \n",
    "    plt.xlabel(\"Survey Response\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(f'{column_name}')\n",
    "    plt.grid(axis='y')\n",
    "    plt.savefig(f'figures/frequency_{column_name}')\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_of_responses_to_survey('I trust artificial intelligence.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_of_responses_to_survey('More vehicles, software, and appliances should make use of AI.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_of_responses_to_survey('I trust companies that do not use AI over companies that do.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_of_responses_to_survey('I would prefer to drive a self-driving car over a regular car.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_of_responses_to_survey('I trust a self driving car to drive safer than I would normally.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_of_responses_to_survey('I believe that increased use of artificial intelligence will make the world a safer place.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_of_responses_to_survey('AI is making our daily lives easier.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned requirements.txt has been generated.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import re\n",
    "\n",
    "# Run pip freeze and capture output\n",
    "result = subprocess.run(['pip', 'freeze'], capture_output=True, text=True)\n",
    "\n",
    "# Use a regex to remove lines that include 'file:///'\n",
    "cleaned_output = re.sub(r' @ file://[^\\n]+', '', result.stdout)\n",
    "\n",
    "# Write the cleaned output to a new requirements.txt file\n",
    "with open('requirements.txt', 'w') as f:\n",
    "    f.write(cleaned_output)\n",
    "\n",
    "print(\"Cleaned requirements.txt has been generated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
